{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicentecipre/miniconda3/envs/prueba/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/vicentecipre/miniconda3/envs/prueba/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/vicentecipre/miniconda3/envs/prueba/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/vicentecipre/miniconda3/envs/prueba/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/vicentecipre/miniconda3/envs/prueba/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/vicentecipre/miniconda3/envs/prueba/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/vicentecipre/miniconda3/envs/prueba/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/vicentecipre/miniconda3/envs/prueba/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/vicentecipre/miniconda3/envs/prueba/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/vicentecipre/miniconda3/envs/prueba/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/vicentecipre/miniconda3/envs/prueba/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/vicentecipre/miniconda3/envs/prueba/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('moore.csv', header=None).values\n",
    "X = data[:,0].reshape(-1, 1) # make it a 2-D array of size N x D where D = 1\n",
    "Y = data[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f20bbe34050>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f20bb01d8d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Since we want a linear model, let's take the log\n",
    "Y = np.log(Y)\n",
    "plt.scatter(X, Y)\n",
    "# that's better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X-X.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 162 samples\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 0s 358us/sample - loss: 324.9804\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 0s 71us/sample - loss: 308.4323\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 0s 57us/sample - loss: 265.2645\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 0s 99us/sample - loss: 185.2425\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 0s 78us/sample - loss: 189.4832\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 0s 67us/sample - loss: 139.7140\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 0s 100us/sample - loss: 141.7452\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 0s 76us/sample - loss: 62.8081\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 0s 78us/sample - loss: 50.6083\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 0s 72us/sample - loss: 42.4691\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 0s 93us/sample - loss: 29.4058\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 0s 72us/sample - loss: 20.3914\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 0s 106us/sample - loss: 17.1829\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 0s 66us/sample - loss: 11.2112\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 0s 114us/sample - loss: 8.0698\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 16/200\n",
      "162/162 [==============================] - 0s 71us/sample - loss: 6.9867\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 17/200\n",
      "162/162 [==============================] - 0s 88us/sample - loss: 5.7083\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 18/200\n",
      "162/162 [==============================] - 0s 75us/sample - loss: 4.0754\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 19/200\n",
      "162/162 [==============================] - 0s 81us/sample - loss: 3.9226\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 20/200\n",
      "162/162 [==============================] - 0s 72us/sample - loss: 2.8962\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 21/200\n",
      "162/162 [==============================] - 0s 101us/sample - loss: 2.4320\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 22/200\n",
      "162/162 [==============================] - 0s 78us/sample - loss: 2.0484\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 23/200\n",
      "162/162 [==============================] - 0s 68us/sample - loss: 1.5320\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 24/200\n",
      "162/162 [==============================] - 0s 82us/sample - loss: 1.3163\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 25/200\n",
      "162/162 [==============================] - 0s 87us/sample - loss: 1.2186\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 26/200\n",
      "162/162 [==============================] - 0s 90us/sample - loss: 1.1276\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 27/200\n",
      "162/162 [==============================] - 0s 90us/sample - loss: 1.3174\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 28/200\n",
      "162/162 [==============================] - 0s 96us/sample - loss: 1.0691\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 29/200\n",
      "162/162 [==============================] - 0s 79us/sample - loss: 1.0713\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 30/200\n",
      "162/162 [==============================] - 0s 69us/sample - loss: 1.0756\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 31/200\n",
      "162/162 [==============================] - 0s 97us/sample - loss: 1.0817\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 32/200\n",
      "162/162 [==============================] - 0s 75us/sample - loss: 1.1232\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 33/200\n",
      "162/162 [==============================] - 0s 51us/sample - loss: 1.0966\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 34/200\n",
      "162/162 [==============================] - 0s 81us/sample - loss: 0.9671\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 35/200\n",
      "162/162 [==============================] - 0s 57us/sample - loss: 0.9694\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 36/200\n",
      "162/162 [==============================] - 0s 81us/sample - loss: 0.9322\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 37/200\n",
      "162/162 [==============================] - 0s 82us/sample - loss: 0.9246\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 38/200\n",
      "162/162 [==============================] - 0s 96us/sample - loss: 0.9038\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 39/200\n",
      "162/162 [==============================] - 0s 78us/sample - loss: 0.8798\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 40/200\n",
      "162/162 [==============================] - 0s 89us/sample - loss: 0.8770\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 41/200\n",
      "162/162 [==============================] - 0s 63us/sample - loss: 0.8751\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 42/200\n",
      "162/162 [==============================] - 0s 76us/sample - loss: 0.8778\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 43/200\n",
      "162/162 [==============================] - 0s 58us/sample - loss: 0.8864\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 44/200\n",
      "162/162 [==============================] - 0s 113us/sample - loss: 0.9110\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 45/200\n",
      "162/162 [==============================] - 0s 90us/sample - loss: 0.9773\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 46/200\n",
      "162/162 [==============================] - 0s 79us/sample - loss: 0.9163\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 47/200\n",
      "162/162 [==============================] - 0s 97us/sample - loss: 0.9075\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 48/200\n",
      "162/162 [==============================] - 0s 106us/sample - loss: 0.9146\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 49/200\n",
      "162/162 [==============================] - 0s 116us/sample - loss: 0.8932\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 50/200\n",
      "162/162 [==============================] - 0s 89us/sample - loss: 0.9171\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 51/200\n",
      "162/162 [==============================] - 0s 92us/sample - loss: 1.3912\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 52/200\n",
      "162/162 [==============================] - 0s 78us/sample - loss: 1.9685\n",
      "\n",
      "Epoch 00053: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 104us/sample - loss: 1.0271\n",
      "\n",
      "Epoch 00054: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 54/200\n",
      "162/162 [==============================] - 0s 81us/sample - loss: 0.9621\n",
      "\n",
      "Epoch 00055: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 55/200\n",
      "162/162 [==============================] - 0s 127us/sample - loss: 0.9632\n",
      "\n",
      "Epoch 00056: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 56/200\n",
      "162/162 [==============================] - 0s 72us/sample - loss: 0.8945\n",
      "\n",
      "Epoch 00057: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 57/200\n",
      "162/162 [==============================] - 0s 90us/sample - loss: 0.9193\n",
      "\n",
      "Epoch 00058: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 58/200\n",
      "162/162 [==============================] - 0s 78us/sample - loss: 0.8868\n",
      "\n",
      "Epoch 00059: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 59/200\n",
      "162/162 [==============================] - 0s 77us/sample - loss: 0.8683\n",
      "\n",
      "Epoch 00060: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 60/200\n",
      "162/162 [==============================] - 0s 57us/sample - loss: 0.8739\n",
      "\n",
      "Epoch 00061: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 61/200\n",
      "162/162 [==============================] - 0s 61us/sample - loss: 0.8813\n",
      "\n",
      "Epoch 00062: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 62/200\n",
      "162/162 [==============================] - 0s 80us/sample - loss: 0.8976\n",
      "\n",
      "Epoch 00063: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 63/200\n",
      "162/162 [==============================] - 0s 81us/sample - loss: 0.8798\n",
      "\n",
      "Epoch 00064: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 64/200\n",
      "162/162 [==============================] - 0s 85us/sample - loss: 0.8704\n",
      "\n",
      "Epoch 00065: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 65/200\n",
      "162/162 [==============================] - 0s 88us/sample - loss: 0.8708\n",
      "\n",
      "Epoch 00066: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 66/200\n",
      "162/162 [==============================] - 0s 94us/sample - loss: 0.8719\n",
      "\n",
      "Epoch 00067: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 67/200\n",
      "162/162 [==============================] - 0s 87us/sample - loss: 0.8714\n",
      "\n",
      "Epoch 00068: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 68/200\n",
      "162/162 [==============================] - 0s 76us/sample - loss: 0.8750\n",
      "\n",
      "Epoch 00069: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 69/200\n",
      "162/162 [==============================] - 0s 63us/sample - loss: 0.8952\n",
      "\n",
      "Epoch 00070: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 70/200\n",
      "162/162 [==============================] - 0s 55us/sample - loss: 0.8935\n",
      "\n",
      "Epoch 00071: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 71/200\n",
      "162/162 [==============================] - 0s 78us/sample - loss: 0.8701\n",
      "\n",
      "Epoch 00072: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 72/200\n",
      "162/162 [==============================] - 0s 92us/sample - loss: 0.8728\n",
      "\n",
      "Epoch 00073: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 73/200\n",
      "162/162 [==============================] - 0s 81us/sample - loss: 0.8726\n",
      "\n",
      "Epoch 00074: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 74/200\n",
      "162/162 [==============================] - 0s 67us/sample - loss: 0.8734\n",
      "\n",
      "Epoch 00075: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 75/200\n",
      "162/162 [==============================] - 0s 70us/sample - loss: 0.8730\n",
      "\n",
      "Epoch 00076: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 76/200\n",
      "162/162 [==============================] - 0s 57us/sample - loss: 0.8743\n",
      "\n",
      "Epoch 00077: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 77/200\n",
      "162/162 [==============================] - 0s 62us/sample - loss: 0.8893\n",
      "\n",
      "Epoch 00078: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 78/200\n",
      "162/162 [==============================] - 0s 79us/sample - loss: 0.8816\n",
      "\n",
      "Epoch 00079: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 79/200\n",
      "162/162 [==============================] - 0s 75us/sample - loss: 0.8713\n",
      "\n",
      "Epoch 00080: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 80/200\n",
      "162/162 [==============================] - 0s 72us/sample - loss: 0.8759\n",
      "\n",
      "Epoch 00081: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 81/200\n",
      "162/162 [==============================] - 0s 59us/sample - loss: 0.8724\n",
      "\n",
      "Epoch 00082: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 82/200\n",
      "162/162 [==============================] - 0s 61us/sample - loss: 0.8743\n",
      "\n",
      "Epoch 00083: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 83/200\n",
      "162/162 [==============================] - 0s 78us/sample - loss: 0.8767\n",
      "\n",
      "Epoch 00084: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 84/200\n",
      "162/162 [==============================] - 0s 69us/sample - loss: 0.8676\n",
      "\n",
      "Epoch 00085: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 85/200\n",
      "162/162 [==============================] - 0s 56us/sample - loss: 0.8821\n",
      "\n",
      "Epoch 00086: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 86/200\n",
      "162/162 [==============================] - 0s 60us/sample - loss: 0.8677\n",
      "\n",
      "Epoch 00087: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 87/200\n",
      "162/162 [==============================] - 0s 78us/sample - loss: 0.8715\n",
      "\n",
      "Epoch 00088: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 88/200\n",
      "162/162 [==============================] - 0s 66us/sample - loss: 0.8720\n",
      "\n",
      "Epoch 00089: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 89/200\n",
      "162/162 [==============================] - 0s 64us/sample - loss: 0.8707\n",
      "\n",
      "Epoch 00090: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 90/200\n",
      "162/162 [==============================] - 0s 72us/sample - loss: 0.8781\n",
      "\n",
      "Epoch 00091: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 91/200\n",
      "162/162 [==============================] - 0s 89us/sample - loss: 0.8916\n",
      "\n",
      "Epoch 00092: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 92/200\n",
      "162/162 [==============================] - 0s 64us/sample - loss: 0.8868\n",
      "\n",
      "Epoch 00093: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 93/200\n",
      "162/162 [==============================] - 0s 69us/sample - loss: 0.8765\n",
      "\n",
      "Epoch 00094: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 94/200\n",
      "162/162 [==============================] - 0s 81us/sample - loss: 0.8778\n",
      "\n",
      "Epoch 00095: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 95/200\n",
      "162/162 [==============================] - 0s 84us/sample - loss: 0.8779\n",
      "\n",
      "Epoch 00096: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 96/200\n",
      "162/162 [==============================] - 0s 69us/sample - loss: 0.8785\n",
      "\n",
      "Epoch 00097: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 97/200\n",
      "162/162 [==============================] - 0s 70us/sample - loss: 0.8762\n",
      "\n",
      "Epoch 00098: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 98/200\n",
      "162/162 [==============================] - 0s 66us/sample - loss: 0.8725\n",
      "\n",
      "Epoch 00099: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 99/200\n",
      "162/162 [==============================] - 0s 70us/sample - loss: 0.8717\n",
      "\n",
      "Epoch 00100: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 100/200\n",
      "162/162 [==============================] - 0s 86us/sample - loss: 0.8841\n",
      "\n",
      "Epoch 00101: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 101/200\n",
      "162/162 [==============================] - 0s 91us/sample - loss: 0.8867\n",
      "\n",
      "Epoch 00102: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 102/200\n",
      "162/162 [==============================] - 0s 85us/sample - loss: 0.8759\n",
      "\n",
      "Epoch 00103: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 103/200\n",
      "162/162 [==============================] - 0s 87us/sample - loss: 0.8898\n",
      "\n",
      "Epoch 00104: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 104/200\n",
      "162/162 [==============================] - 0s 81us/sample - loss: 0.9237\n",
      "\n",
      "Epoch 00105: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 105/200\n",
      "162/162 [==============================] - 0s 75us/sample - loss: 0.8881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00106: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 106/200\n",
      "162/162 [==============================] - 0s 81us/sample - loss: 0.8664\n",
      "\n",
      "Epoch 00107: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 107/200\n",
      "162/162 [==============================] - 0s 83us/sample - loss: 0.8825\n",
      "\n",
      "Epoch 00108: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 108/200\n",
      "162/162 [==============================] - 0s 69us/sample - loss: 0.8837\n",
      "\n",
      "Epoch 00109: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 109/200\n",
      "162/162 [==============================] - 0s 61us/sample - loss: 0.8723\n",
      "\n",
      "Epoch 00110: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 110/200\n",
      "162/162 [==============================] - 0s 55us/sample - loss: 0.8752\n",
      "\n",
      "Epoch 00111: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 111/200\n",
      "162/162 [==============================] - 0s 78us/sample - loss: 0.8730\n",
      "\n",
      "Epoch 00112: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 112/200\n",
      "162/162 [==============================] - 0s 89us/sample - loss: 0.8850\n",
      "\n",
      "Epoch 00113: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 113/200\n",
      "162/162 [==============================] - 0s 79us/sample - loss: 0.8735\n",
      "\n",
      "Epoch 00114: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 114/200\n",
      "162/162 [==============================] - 0s 98us/sample - loss: 0.8778\n",
      "\n",
      "Epoch 00115: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 115/200\n",
      "162/162 [==============================] - 0s 88us/sample - loss: 0.8907\n",
      "\n",
      "Epoch 00116: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 116/200\n",
      "162/162 [==============================] - 0s 80us/sample - loss: 0.8782\n",
      "\n",
      "Epoch 00117: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 117/200\n",
      "162/162 [==============================] - 0s 59us/sample - loss: 0.8755\n",
      "\n",
      "Epoch 00118: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 118/200\n",
      "162/162 [==============================] - 0s 58us/sample - loss: 0.8753\n",
      "\n",
      "Epoch 00119: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 119/200\n",
      "162/162 [==============================] - 0s 71us/sample - loss: 0.8813\n",
      "\n",
      "Epoch 00120: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 120/200\n",
      "162/162 [==============================] - 0s 83us/sample - loss: 0.9210\n",
      "\n",
      "Epoch 00121: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 121/200\n",
      "162/162 [==============================] - 0s 91us/sample - loss: 0.9253\n",
      "\n",
      "Epoch 00122: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 122/200\n",
      "162/162 [==============================] - 0s 79us/sample - loss: 0.8771\n",
      "\n",
      "Epoch 00123: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 123/200\n",
      "162/162 [==============================] - 0s 86us/sample - loss: 0.8783\n",
      "\n",
      "Epoch 00124: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 124/200\n",
      "162/162 [==============================] - 0s 64us/sample - loss: 0.8760\n",
      "\n",
      "Epoch 00125: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 125/200\n",
      "162/162 [==============================] - 0s 67us/sample - loss: 0.8684\n",
      "\n",
      "Epoch 00126: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 126/200\n",
      "162/162 [==============================] - 0s 65us/sample - loss: 0.8938\n",
      "\n",
      "Epoch 00127: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 127/200\n",
      "162/162 [==============================] - 0s 78us/sample - loss: 0.8918\n",
      "\n",
      "Epoch 00128: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 128/200\n",
      "162/162 [==============================] - 0s 92us/sample - loss: 0.8730\n",
      "\n",
      "Epoch 00129: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 129/200\n",
      "162/162 [==============================] - 0s 70us/sample - loss: 0.8706\n",
      "\n",
      "Epoch 00130: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 130/200\n",
      "162/162 [==============================] - 0s 95us/sample - loss: 0.8724\n",
      "\n",
      "Epoch 00131: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 131/200\n",
      "162/162 [==============================] - 0s 57us/sample - loss: 0.9032\n",
      "\n",
      "Epoch 00132: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 132/200\n",
      "162/162 [==============================] - 0s 60us/sample - loss: 0.9005\n",
      "\n",
      "Epoch 00133: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 133/200\n",
      "162/162 [==============================] - 0s 69us/sample - loss: 0.8737\n",
      "\n",
      "Epoch 00134: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 134/200\n",
      "162/162 [==============================] - 0s 67us/sample - loss: 0.8778\n",
      "\n",
      "Epoch 00135: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 135/200\n",
      "162/162 [==============================] - 0s 58us/sample - loss: 0.8911\n",
      "\n",
      "Epoch 00136: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 136/200\n",
      "162/162 [==============================] - 0s 61us/sample - loss: 0.8740\n",
      "\n",
      "Epoch 00137: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 137/200\n",
      "162/162 [==============================] - 0s 75us/sample - loss: 0.8995\n",
      "\n",
      "Epoch 00138: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 138/200\n",
      "162/162 [==============================] - 0s 75us/sample - loss: 0.8934\n",
      "\n",
      "Epoch 00139: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 139/200\n",
      "162/162 [==============================] - 0s 69us/sample - loss: 0.8657\n",
      "\n",
      "Epoch 00140: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 140/200\n",
      "162/162 [==============================] - 0s 65us/sample - loss: 0.8797\n",
      "\n",
      "Epoch 00141: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 141/200\n",
      "162/162 [==============================] - 0s 64us/sample - loss: 0.8723\n",
      "\n",
      "Epoch 00142: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 142/200\n",
      "162/162 [==============================] - 0s 65us/sample - loss: 0.8849\n",
      "\n",
      "Epoch 00143: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 143/200\n",
      "162/162 [==============================] - 0s 66us/sample - loss: 0.9205\n",
      "\n",
      "Epoch 00144: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 144/200\n",
      "162/162 [==============================] - 0s 53us/sample - loss: 0.8849\n",
      "\n",
      "Epoch 00145: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 145/200\n",
      "162/162 [==============================] - 0s 60us/sample - loss: 0.8841\n",
      "\n",
      "Epoch 00146: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 146/200\n",
      "162/162 [==============================] - 0s 74us/sample - loss: 0.9039\n",
      "\n",
      "Epoch 00147: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 147/200\n",
      "162/162 [==============================] - 0s 74us/sample - loss: 0.8734\n",
      "\n",
      "Epoch 00148: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 148/200\n",
      "162/162 [==============================] - 0s 67us/sample - loss: 0.8926\n",
      "\n",
      "Epoch 00149: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 149/200\n",
      "162/162 [==============================] - 0s 88us/sample - loss: 0.8833\n",
      "\n",
      "Epoch 00150: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 150/200\n",
      "162/162 [==============================] - 0s 91us/sample - loss: 0.8707\n",
      "\n",
      "Epoch 00151: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 151/200\n",
      "162/162 [==============================] - 0s 81us/sample - loss: 0.8747\n",
      "\n",
      "Epoch 00152: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 152/200\n",
      "162/162 [==============================] - 0s 76us/sample - loss: 0.8746\n",
      "\n",
      "Epoch 00153: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 153/200\n",
      "162/162 [==============================] - 0s 60us/sample - loss: 0.8708\n",
      "\n",
      "Epoch 00154: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 154/200\n",
      "162/162 [==============================] - 0s 77us/sample - loss: 0.8767\n",
      "\n",
      "Epoch 00155: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 155/200\n",
      "162/162 [==============================] - 0s 89us/sample - loss: 0.8839\n",
      "\n",
      "Epoch 00156: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 156/200\n",
      "162/162 [==============================] - 0s 61us/sample - loss: 0.8901\n",
      "\n",
      "Epoch 00157: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 157/200\n",
      "162/162 [==============================] - 0s 60us/sample - loss: 0.8870\n",
      "\n",
      "Epoch 00158: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 87us/sample - loss: 0.8719\n",
      "\n",
      "Epoch 00159: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 159/200\n",
      "162/162 [==============================] - 0s 71us/sample - loss: 0.8754\n",
      "\n",
      "Epoch 00160: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 160/200\n",
      "162/162 [==============================] - 0s 92us/sample - loss: 0.9141\n",
      "\n",
      "Epoch 00161: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 161/200\n",
      "162/162 [==============================] - 0s 93us/sample - loss: 0.8789\n",
      "\n",
      "Epoch 00162: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 162/200\n",
      "162/162 [==============================] - 0s 90us/sample - loss: 0.8849\n",
      "\n",
      "Epoch 00163: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 163/200\n",
      "162/162 [==============================] - 0s 88us/sample - loss: 0.8915\n",
      "\n",
      "Epoch 00164: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 164/200\n",
      "162/162 [==============================] - 0s 79us/sample - loss: 0.8853\n",
      "\n",
      "Epoch 00165: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 165/200\n",
      "162/162 [==============================] - 0s 74us/sample - loss: 0.8691\n",
      "\n",
      "Epoch 00166: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 166/200\n",
      "162/162 [==============================] - 0s 67us/sample - loss: 0.8768\n",
      "\n",
      "Epoch 00167: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 167/200\n",
      "162/162 [==============================] - 0s 61us/sample - loss: 0.8685\n",
      "\n",
      "Epoch 00168: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 168/200\n",
      "162/162 [==============================] - 0s 67us/sample - loss: 0.8756\n",
      "\n",
      "Epoch 00169: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 169/200\n",
      "162/162 [==============================] - 0s 65us/sample - loss: 0.8731\n",
      "\n",
      "Epoch 00170: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 170/200\n",
      "162/162 [==============================] - 0s 62us/sample - loss: 0.8712\n",
      "\n",
      "Epoch 00171: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 171/200\n",
      "162/162 [==============================] - 0s 63us/sample - loss: 0.8718\n",
      "\n",
      "Epoch 00172: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 172/200\n",
      "162/162 [==============================] - 0s 55us/sample - loss: 0.8711\n",
      "\n",
      "Epoch 00173: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 173/200\n",
      "162/162 [==============================] - 0s 72us/sample - loss: 0.8781\n",
      "\n",
      "Epoch 00174: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 174/200\n",
      "162/162 [==============================] - 0s 75us/sample - loss: 0.8777\n",
      "\n",
      "Epoch 00175: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 175/200\n",
      "162/162 [==============================] - 0s 84us/sample - loss: 0.8777\n",
      "\n",
      "Epoch 00176: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 176/200\n",
      "162/162 [==============================] - 0s 60us/sample - loss: 0.8737\n",
      "\n",
      "Epoch 00177: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 177/200\n",
      "162/162 [==============================] - 0s 60us/sample - loss: 0.8733\n",
      "\n",
      "Epoch 00178: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 178/200\n",
      "162/162 [==============================] - 0s 79us/sample - loss: 0.8710\n",
      "\n",
      "Epoch 00179: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 179/200\n",
      "162/162 [==============================] - 0s 64us/sample - loss: 0.8706\n",
      "\n",
      "Epoch 00180: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 180/200\n",
      "162/162 [==============================] - 0s 84us/sample - loss: 0.8714\n",
      "\n",
      "Epoch 00181: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 181/200\n",
      "162/162 [==============================] - 0s 106us/sample - loss: 0.8712\n",
      "\n",
      "Epoch 00182: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 182/200\n",
      "162/162 [==============================] - 0s 77us/sample - loss: 0.8702\n",
      "\n",
      "Epoch 00183: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 183/200\n",
      "162/162 [==============================] - 0s 118us/sample - loss: 0.8772\n",
      "\n",
      "Epoch 00184: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 184/200\n",
      "162/162 [==============================] - 0s 82us/sample - loss: 0.8710\n",
      "\n",
      "Epoch 00185: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 185/200\n",
      "162/162 [==============================] - 0s 139us/sample - loss: 0.8715\n",
      "\n",
      "Epoch 00186: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 186/200\n",
      "162/162 [==============================] - 0s 83us/sample - loss: 0.8735\n",
      "\n",
      "Epoch 00187: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 187/200\n",
      "162/162 [==============================] - 0s 103us/sample - loss: 0.8711\n",
      "\n",
      "Epoch 00188: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 188/200\n",
      "162/162 [==============================] - 0s 155us/sample - loss: 0.8697\n",
      "\n",
      "Epoch 00189: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 189/200\n",
      "162/162 [==============================] - 0s 83us/sample - loss: 0.8710\n",
      "\n",
      "Epoch 00190: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 190/200\n",
      "162/162 [==============================] - 0s 99us/sample - loss: 0.8711\n",
      "\n",
      "Epoch 00191: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 191/200\n",
      "162/162 [==============================] - 0s 75us/sample - loss: 0.8767\n",
      "\n",
      "Epoch 00192: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 192/200\n",
      "162/162 [==============================] - 0s 121us/sample - loss: 0.8737\n",
      "\n",
      "Epoch 00193: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 193/200\n",
      "162/162 [==============================] - 0s 72us/sample - loss: 0.8756\n",
      "\n",
      "Epoch 00194: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 194/200\n",
      "162/162 [==============================] - 0s 75us/sample - loss: 0.8922\n",
      "\n",
      "Epoch 00195: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 195/200\n",
      "162/162 [==============================] - 0s 84us/sample - loss: 0.8810\n",
      "\n",
      "Epoch 00196: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 196/200\n",
      "162/162 [==============================] - 0s 97us/sample - loss: 0.8830\n",
      "\n",
      "Epoch 00197: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 197/200\n",
      "162/162 [==============================] - 0s 79us/sample - loss: 0.9076\n",
      "\n",
      "Epoch 00198: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 198/200\n",
      "162/162 [==============================] - 0s 83us/sample - loss: 0.8780\n",
      "\n",
      "Epoch 00199: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 199/200\n",
      "162/162 [==============================] - 0s 71us/sample - loss: 0.8756\n",
      "\n",
      "Epoch 00200: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 200/200\n",
      "162/162 [==============================] - 0s 102us/sample - loss: 0.8764\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1,)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer = tf.keras.optimizers.SGD(0.001,0.9), loss = \"mse\")\n",
    "# model.compile(optimizer = \"adam\", loss = \"mse\")\n",
    "def schedule(epoch, lr):\n",
    "    if epoch >= 50:\n",
    "        return 0.0001\n",
    "    return 0.001\n",
    " \n",
    "\n",
    "scheduler = tf.keras.callbacks.LearningRateScheduler(schedule,1)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "r = model.fit(X, Y, epochs=200, callbacks=[scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2090cbdfd0>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAYi0lEQVR4nO3df3Dc9Z3f8edLu+sVtmzZxrLjn7EJJmDSYHw+So9Am3C5ANOeSVtSM53Ec0fPdx3oJO21c+Qy06YzxwxJSzLNXEvqFC4mk4TQBgZP66QhJEcmaSCRwfgHhliYH5at2DLGlm0syZLe/WO/shexsn7urvT9vh4zmv3uZ7+rfeu7q5c+en+/u19FBGZmli4N9S7AzMwmn8PdzCyFHO5mZinkcDczSyGHu5lZCuXrXQDAggULYuXKlfUuw8xsWtmxY8exiGipdNuUCPeVK1fS2tpa7zLMzKYVSW8Md5vbMmZmKeRwNzNLIYe7mVkKOdzNzFLI4W5mlkIOdzOzFHK4m5ml0LQO95d/28X9P3iZru5z9S7FzGxKmdbhfvD4Wb7+zKu8evR0vUsxM5tSpnW4r1owC4ADnWfqXImZ2dQyrcN9xfyZ5BrEa8cc7mZm5aZ1uM/IN7Bi/kwOHHNbxsys3LQOd4DLFsxyW8bMbIhpH+6rFszitWNnGBjwib7NzAZN+3C/rKWJnr4BDp04W+9SzMymjBSEe+mIGe9UNTO7IDXhfqDTO1XNzAZN+3BvaSoyu5jngGfuZmbnTftwl8Ty+TM5ePydepdiZjZlTPtwB2i+pMCp7r56l2FmNmWMGO6SGiX9StKLkvZK+o/J+CpJz0naL+l7kmYk48Xkelty+8rq/ggwuzHvcDczKzOamXsP8LGIuAZYC9wi6XrgS8BXI2I18DZwV7L+XcDbEXE58NVkvaqa3VjglD8Z0szsvBHDPUoGD0UpJF8BfAz4X8n4VuD2ZHlDcp3k9psladIqrsAzdzOzdxtVz11STtJO4CjwFPAqcCIiBhO1HViaLC8FDgIkt58ELq3wPTdLapXU2tnZOaEfYk5jntO9fX6XqplZYlThHhH9EbEWWAZcB1xVabXkstIs/T2pGxFbImJ9RKxvaWkZbb0VzW4sEAFnej17NzODMR4tExEngL8FrgfmSsonNy0DDifL7cBygOT2ZuD4ZBQ7nKbGUhluzZiZlYzmaJkWSXOT5UuA3wf2AT8F/mmy2ibgyWR5W3Kd5PafRERV+yWzHe5mZu+SH3kVFgNbJeUo/TF4LCL+t6SXgEcl/RXwAvBQsv5DwLcktVGasW+sQt3vMruxAOAjZszMEiOGe0TsAq6tMH6AUv996Hg3cMekVDdKnrmbmb1bKt6hOicJ9y7P3M3MgJSE+4W2jGfuZmaQmnB3W8bMrFwqwv2SQo5cgzjd47aMmRmkJNwl+SMIzMzKpCLcAZqKDnczs0GpCXd/MqSZ2QUpCvc8XZ65m5kBKQr3Oe65m5mdl5pwd1vGzOyCFIW7Z+5mZoNSFe6ne/qo8gdQmplNCykK9wL9A8HZc/31LsXMrO5SE+5NRX8EgZnZoNSE+4XPl/FOVTOz1IT7nOSTIX2su5lZisK9sZADoNs9dzOz9IR7sVD6UXr6BupciZlZ/aUn3PNJuJ9zuJuZpSjcS22Znj63ZczMUhTubsuYmQ1KT7i7525mdt6I4S5puaSfStonaa+kzybjX5R0SNLO5Ou2svt8XlKbpFckfaKaP8Cg820ZHy1jZkZ+FOv0AX8eEc9Lmg3skPRUcttXI+I/l68saQ2wEbgaWAL8WNIVEVHV1HVbxszsghFn7hHRERHPJ8ungH3A0ovcZQPwaET0RMRrQBtw3WQUezEOdzOzC8bUc5e0ErgWeC4ZukfSLkkPS5qXjC0FDpbdrZ0KfwwkbZbUKqm1s7NzzIVX+H7MyDf4aBkzM8YQ7pKagO8Dn4uILuBB4APAWqADeGBw1Qp3f8/n8EbElohYHxHrW1paxlx4JcV8g49zNzNjlOEuqUAp2L8dEY8DRMSRiOiPiAHgG1xovbQDy8vuvgw4PHklD6+Yz7ktY2bG6I6WEfAQsC8ivlI2vrhstU8Ce5LlbcBGSUVJq4DVwK8mr+ThFd2WMTMDRne0zA3Ap4HdknYmY38J3ClpLaWWy+vAnwJExF5JjwEvUTrS5u5qHykzqFho8MzdzIxRhHtE/JzKffTtF7nPfcB9E6hrXIr5nHvuZmak6B2q4LaMmdmgFIa7Z+5mZqkK98aCj5YxM4OUhXvpOHe3ZczM0hXuhRy9nrmbmaUs3N1zNzMDUhnubsuYmaUs3H2cu5kZpC3c/Q5VMzMgbeGeb6C3f4CBgfd8CKWZWaakLNxLp9rr7ffs3cyyLWXhnpyNyX13M8u4dIV7YfBUez5ixsyyLV3hnrRlvFPVzLIuZeHumbuZGaQ03LvdczezjEtXuBfcljEzg7SFu9syZmZAasPdM3czy7aUhXvSlnHP3cwyLl3h7uPczcyAUYS7pOWSfippn6S9kj6bjM+X9JSk/cnlvGRckr4mqU3SLknrqv1DDHJbxsysZDQz9z7gzyPiKuB64G5Ja4B7gacjYjXwdHId4FZgdfK1GXhw0qseht/EZGZWMmK4R0RHRDyfLJ8C9gFLgQ3A1mS1rcDtyfIG4JEoeRaYK2nxpFdewfm2jM+jamYZN6aeu6SVwLXAc8CiiOiA0h8AYGGy2lLgYNnd2pOxod9rs6RWSa2dnZ1jr7wCt2XMzEpGHe6SmoDvA5+LiK6LrVph7D0fsB4RWyJifUSsb2lpGW0ZFzUj53A3M4NRhrukAqVg/3ZEPJ4MHxlstySXR5PxdmB52d2XAYcnp9wR6/R5VM3MGN3RMgIeAvZFxFfKbtoGbEqWNwFPlo1/Jjlq5nrg5GD7phaK+QYf525mmZcfxTo3AJ8GdkvamYz9JXA/8Jiku4A3gTuS27YDtwFtwDvAH01qxSMoFnKeuZtZ5o0Y7hHxcyr30QFurrB+AHdPsK5x88zdzCxl71CFUri3dZ7mU1//JQePv1PvcszM6mI0bZlppZjPsav9JAB7D3exfP7MOldkZlZ7qZu5NxYu/EhnevrqWImZWf2kLtwXNBVZOvcSAM70OtzNLJtSF+4PfOoanrj79wA47Zm7mWVU6nrusxsLNBXz5BrktoyZZVbqZu5QeqfqrBk5zvT4eHczy6ZUhjtAUzHvtoyZZVZqw31WMe+2jJllVqrD3TN3M8uqFId7zjN3M8us9Ib7jLx3qJpZZqU23L1D1cyyLLXhPquY5x2/Q9XMMirV4e62jJllVWrDvamYo7d/gF6fT9XMMii14T6rWPpkBR8xY2ZZlPpw905VM8ui9Ib7jGTm7p2qZpZB6Q33Yg5wW8bMsim14d50vi3jI2bMLHtSG+7eoWpmWTZiuEt6WNJRSXvKxr4o6ZCkncnXbWW3fV5Sm6RXJH2iWoWPpMk7VM0sw0Yzc/8mcEuF8a9GxNrkazuApDXARuDq5D7/TVJusoodC8/czSzLRgz3iPgZcHyU328D8GhE9ETEa0AbcN0E6hs371A1syybSM/9Hkm7krbNvGRsKXCwbJ32ZOw9JG2W1CqptbOzcwJlVFbM5yjkxJle71A1s+wZb7g/CHwAWAt0AA8k46qwblT6BhGxJSLWR8T6lpaWcZZxcT4bk5ll1bjCPSKORER/RAwA3+BC66UdWF626jLg8MRKHL9ZM/yxv2aWTeMKd0mLy65+Ehg8kmYbsFFSUdIqYDXwq4mVOH4+G5OZZdVoDoX8LvBL4IOS2iXdBXxZ0m5Ju4CPAv8aICL2Ao8BLwE/BO6OiLo1vWcV87x27Az3fOd53nzrnXqVYWZWc/mRVoiIOysMP3SR9e8D7ptIUZOlqZjnhTdP8Jsjp7n5qoWsuHRmvUsyM6uJ1L5DFeDDy5pZvbAJgJ5z/lx3M8uOVIf7v/vElXzvT/8eAD0+aYeZZUiqwx2gmC/9iD19Pt7dzLIjO+HutoyZZUjqwz2fayDfILo9czezDEl9uENp9u6Zu5llSTbCvZDzDlUzy5RshHu+wTtUzSxTMhTunrmbWXZkJNxz7rmbWaZkI9wLbsuYWbZkItwb896hambZkolwLxYa6D7nmbuZZUc2wt07VM0sYzIS7m7LmFm2ZCTcvUPVzLIlG+Fe8McPmFm2ZCPc3ZYxs4zJSLi7LWNm2ZKNcC/k6D43QETUuxQzs5rIRrgnJ+zo7XdrxsyyYcRwl/SwpKOS9pSNzZf0lKT9yeW8ZFySviapTdIuSeuqWfxoXTjVnsPdzLJhNDP3bwK3DBm7F3g6IlYDTyfXAW4FVidfm4EHJ6fMiSkWcoBPtWdm2TFiuEfEz4DjQ4Y3AFuT5a3A7WXjj0TJs8BcSYsnq9jx8kmyzSxrxttzXxQRHQDJ5cJkfClwsGy99mTsPSRtltQqqbWzs3OcZYyO2zJmljWTvUNVFcYqHqISEVsiYn1ErG9paZnkMt6tmHdbxsyyZbzhfmSw3ZJcHk3G24HlZestAw6Pv7zJUSy4LWNm2TLecN8GbEqWNwFPlo1/Jjlq5nrg5GD7pp4ak5l7t2fuZpYR+ZFWkPRd4B8ACyS1A/8BuB94TNJdwJvAHcnq24HbgDbgHeCPqlDzmHnmbmZZM2K4R8Sdw9x0c4V1A7h7okVNNu9QNbOsycg7VJMdqg53M8uIjIR7MnP3qfbMLCOyEe4Ft2XMLFuyEe5uy5hZxmQi3Bt9tIyZZUwmwn1GrvRj+jh3M8uKTIS7JJ+NycwyJRPhDsmp9jxzN7OMyE64F3ySbDPLjuyEu9syZpYhGQt3z9zNLBsyFO4599zNLDMyE+6NBbdlzCw7MhPunrmbWZZkJ9w9czezDMlOuHuHqpllSIbC3ce5m1l2ZCbcL22awZGubvoHot6lmJlVXWbC/e8sbead3n5e7Txd71LMzKouM+H+4WXNALx48ESdKzEzq77MhPtlC5qYNSPHrvaT9S7FzKzqMhPuDQ3iQ0ub2XXI4W5m6TehcJf0uqTdknZKak3G5kt6StL+5HLe5JQ6cdcsn8u+w130+qgZM0u5yZi5fzQi1kbE+uT6vcDTEbEaeDq5PiV8eFkzvf0DvPLbU/UuxcysqqrRltkAbE2WtwK3V+ExxuWaZXMB2PHG8TpXYmZWXRMN9wB+JGmHpM3J2KKI6ABILhdWuqOkzZJaJbV2dnZOsIzRWTbvElYtmMXTLx+tyeOZmdXLRMP9hohYB9wK3C3pptHeMSK2RMT6iFjf0tIywTJGRxIfX7OIZw+8RVf3uZo8pplZPUwo3CPicHJ5FHgCuA44ImkxQHI5pabJH1+ziHP9wTOv1Oa/BTOzehh3uEuaJWn24DLwB8AeYBuwKVltE/DkRIucTOtWzGP+rBn8eN+RepdiZlY1+QncdxHwhKTB7/OdiPihpF8Dj0m6C3gTuGPiZU6eXIP46AcX8uN9R4gIkvrNzFJl3OEeEQeAayqMvwXcPJGiqm3d++fy/efbOXj8LCsunVnvcszMJl1m3qFa7uolpc+Z2XvY71Y1s3TKZLhf+b7Z5BrE3sNd9S7FzKwqMhnujYUcH2iZ5Zm7maVWJsMd4ENLmj1zN7PUymy4r1kyh6Onejh6qrvepZiZTbrMhvuFnaqevZtZ+mQ23NcsmYPkMzOZWTplNtybLynwoSXN/Hz/sXqXYmY26TIb7gB//4oWXjh4gpNn/SFiZpYumQ73m65ooX8g+H9tnr2bWbpkOtyvXTGXpmKen+33J0SaWbpkOtwLuQZuuPxS/vaVTp9X1cxSJdPhDvDPfnc5HSe7+av/81K9SzEzmzSZD/ePXbmIP7lxFY/88g227+6odzlmZpMi8+EO8Be3XMkVi5r465+0ERH1LsfMbMIc7kA+18Cm31vJSx1d7Hjj7XqXY2Y2YQ73xO1rlzK7Mc8jv3yj3qWYmU2Ywz0xq5jnjt9ZzvbdHez0RxKY2TTncC/zrz52Oe9rbuTPvrXDnxZpZtOaw73MvFkz+O+f/h1OnO3l5gee4cs/fJnOUz31LsvMbMwc7kNcvaSZx//lDdy4egEPPvMqH/nST7j/By/Tfa6/3qWZmY2aqnXon6RbgP8C5ID/ERH3D7fu+vXro7W1tSp1TMSBztP89U/aePyFQyxubuTyhU1cvaSZO69bzvsvnVXv8sws4yTtiIj1FW+rRrhLygG/AT4OtAO/Bu6MiIpvA52q4T7oF23H+JtfvEbn6V72HDpJ/0DQMrvIVYvncNX7ZnPV4jmsuHQmzZcUmNNYoKmYZ0a+gdM9ffT1DzBv5gwaGlTvH4OI4NCJs7x48CSHT5zlo1cu5PKFTfUuy8zG6WLhnq/SY14HtEXEgaSAR4ENwLR8j/8Nly/ghssXAPDbk91s393BSx1d7Ovo4m9+8Ra9/Rf/XJp8gyjkGmgQNEiQXDYIlFyCzt+uwfUADfmbUH5djO0PxumePo6f6T1//b7t+2i+pECuQefrGVyWSo8ldP4xRane849a+lHMbAI2/u4K/uSmyyb9+1Yr3JcCB8uutwN/t3wFSZuBzQArVqyoUhmT733NjfzxR1adv36uf4DXjp3h0Ntn6eo+R1d3H6e7++jp66epmCfXII6d7qG3b4CBgAgYSP5bGohgICIZAwgGBkrjwYX1zouKi6XrEWjoX4IhGgsNrFnSzDXLmlnQVGT77g7a3z5L/0DQH8HAQNA/EEmdpRoG/7MrLV943MHbCZzwZhOwcE6xKt+3WuFe6df9XXkUEVuALVBqy1Spjqor5Bq4YtFsrlg0u96ljNm/uHHyZwtmNjVU62iZdmB52fVlwOEqPZaZmQ1RrXD/NbBa0ipJM4CNwLYqPZaZmQ1RlbZMRPRJugf4v5QOhXw4IvZW47HMzOy9qtVzJyK2A9ur9f3NzGx4foeqmVkKOdzNzFLI4W5mlkIOdzOzFKraB4eNqQipExjvKZAWAMcmsZzJNFVrc11jM1Xrgqlbm+sam/HW9f6IaKl0w5QI94mQ1DrcB+fU21StzXWNzVStC6Zuba5rbKpRl9syZmYp5HA3M0uhNIT7lnoXcBFTtTbXNTZTtS6YurW5rrGZ9Lqmfc/dzMzeKw0zdzMzG8LhbmaWQtM63CXdIukVSW2S7q1jHcsl/VTSPkl7JX02Gf+ipEOSdiZft9Whttcl7U4evzUZmy/pKUn7k8t5dajrg2XbZaekLkmfq8c2k/SwpKOS9pSNVdxGKvla8prbJWldjev6T5JeTh77CUlzk/GVks6Wbbev17iuYZ83SZ9Pttcrkj5RrbouUtv3yup6XdLOZLyW22y4jKje6ywipuUXpY8SfhW4DJgBvAisqVMti4F1yfJsSicHXwN8Efi3dd5OrwMLhox9Gbg3Wb4X+NIUeC5/C7y/HtsMuAlYB+wZaRsBtwE/oHS2seuB52pc1x8A+WT5S2V1rSxfrw7bq+LzlvwevAgUgVXJ72yulrUNuf0B4N/XYZsNlxFVe51N55n7+ZNwR0QvMHgS7pqLiI6IeD5ZPgXso3Qe2alqA7A1Wd4K3F7HWgBuBl6NiPG+S3lCIuJnwPEhw8Ntow3AI1HyLDBX0uJa1RURP4qIvuTqs5TOclZTw2yv4WwAHo2Inoh4DWij9Ltb89pUOsnwp4DvVuvxh3ORjKja62w6h3ulk3DXPVAlrQSuBZ5Lhu5J/q16uB7tD0rnrv2RpB0qnZQcYFFEdEDpRQcsrENd5Tby7l+4em8zGH4bTaXX3R9Tmt0NWiXpBUnPSLqxDvVUet6m0va6ETgSEfvLxmq+zYZkRNVeZ9M53Ec8CXetSWoCvg98LiK6gAeBDwBrgQ5K/xLW2g0RsQ64Fbhb0k11qGFYKp2G8Q+B/5kMTYVtdjFT4nUn6QtAH/DtZKgDWBER1wL/BviOpDk1LGm4521KbK/Enbx7ElHzbVYhI4ZdtcLYmLbbdA73KXUSbkkFSk/atyPicYCIOBIR/RExAHyDKv47OpyIOJxcHgWeSGo4MvgvXnJ5tNZ1lbkVeD4ijsDU2GaJ4bZR3V93kjYB/xD455E0aJO2x1vJ8g5Kve0ralXTRZ63um8vAEl54B8D3xscq/U2q5QRVPF1Np3DfcqchDvp5T0E7IuIr5SNl/fIPgnsGXrfKtc1S9LswWVKO+P2UNpOm5LVNgFP1rKuId41m6r3Nisz3DbaBnwmOZrheuDk4L/VtSDpFuAvgD+MiHfKxlsk5ZLly4DVwIEa1jXc87YN2CipKGlVUtevalVXmd8HXo6I9sGBWm6z4TKCar7OarGnuFpflPYo/4bSX9wv1LGOj1D6l2kXsDP5ug34FrA7Gd8GLK5xXZdROlLhRWDv4DYCLgWeBvYnl/PrtN1mAm8BzWVjNd9mlP64dADnKM2Y7hpuG1H6d/m/Jq+53cD6GtfVRqkXO/g6+3qy7j9JnuMXgeeBf1TjuoZ93oAvJNvrFeDWWj+Xyfg3gT8bsm4tt9lwGVG115k/fsDMLIWmc1vGzMyG4XA3M0shh7uZWQo53M3MUsjhbmaWQg53M7MUcribmaXQ/wc4tCGUFEQqJAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['loss'], label='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tensorflow.python.keras.layers.core.Dense object at 0x7f20b86d5cd0>]\n",
      "[array([[0.34623474]], dtype=float32), array([17.7774], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# Get the slope of the line\n",
    "# The slope of the line is related to the doubling rate of transistor count\n",
    "print(model.layers) # Note: there is only 1 layer, the \"Input\" layer doesn't count\n",
    "print(model.layers[0].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34623474"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model.layers[0].get_weights()[0][0,0]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to double: 2.001957350983146\n"
     ]
    }
   ],
   "source": [
    "print(\"Time to double:\", np.log(2) / a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3416824873873133 17.764939393631792\n",
      "Time to double: 2.0286295205239187\n"
     ]
    }
   ],
   "source": [
    "# If you know the analytical solution\n",
    "X = np.array(X).flatten()\n",
    "Y = np.array(Y)\n",
    "denominator = X.dot(X) - X.mean() * X.sum()\n",
    "a = ( X.dot(Y) - Y.mean()*X.sum() ) / denominator\n",
    "b = ( Y.mean() * X.dot(X) - X.mean() * X.dot(Y) ) / denominator\n",
    "print(a, b)\n",
    "print(\"Time to double:\", np.log(2) / a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2090c98f90>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make sure the line fits our data\n",
    "Yhat = model.predict(X).flatten()\n",
    "plt.scatter(X, Y)\n",
    "plt.plot(X, Yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manual calculation\n",
    "\n",
    "# Get the weights\n",
    "w, b = model.layers[0].get_weights()\n",
    "\n",
    "# Reshape X because we flattened it again earlier\n",
    "X = X.reshape(-1, 1)\n",
    "\n",
    "# (N x 1) x (1 x 1) + (1) --> (N x 1)\n",
    "Yhat2 = (X.dot(w) + b).flatten()\n",
    "\n",
    "# Don't use == for floating points\n",
    "np.allclose(Yhat, Yhat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
